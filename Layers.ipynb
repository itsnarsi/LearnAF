{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "\n",
    "import arrayfire as af\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from LearnAF import *\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "af.set_backend('cpu')\n",
    "\n",
    "DF = pd.read_csv('/home/narsi/Downloads/train.csv')\n",
    "Data = np.asarray(DF, dtype = np.float32)/255.0\n",
    "Data = Data[1:]\n",
    "labels = np.asarray(DF['label'], dtype = np.float32)\n",
    "classes = np.asarray(to_categorical(labels), dtype = np.float32)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "syn0 = np.array(2*np.random.random((Data.shape[1],64)) - 1, dtype = np.float32)\n",
    "W1 = Variable(af.np_to_af_array(syn0),name='W1')\n",
    "b1 = Variable(af.constant(0,1),name='b1')\n",
    "\n",
    "syn0 = np.array(2*np.random.random((64,16)) - 1, dtype = np.float32)\n",
    "W2 = Variable(af.np_to_af_array(syn0),name='W2')\n",
    "b2 = Variable(af.constant(0,1),name='b2')\n",
    "\n",
    "syn0 = np.array(2*np.random.random((16,10)) - 1, dtype = np.float32)\n",
    "W3 = Variable(af.np_to_af_array(syn0),name='W3')\n",
    "b3 = Variable(af.constant(0,1),name='b3')\n",
    "\n",
    "w = [W1,b1,W2,b2,W3,b3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learner(X,W):\n",
    "    # 784 -> 64\n",
    "    X1 = sigmoid(add(matmul(X,W[0]),W[1]))\n",
    "    # 64 -> 16\n",
    "    X2 = sigmoid(add(matmul(X1,W[2]),W[3]))\n",
    "    # 16 -> 10\n",
    "    YP = sigmoid(add(matmul(X2,W[4]),W[5]))\n",
    "    return YP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place Holders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xin = Constant(af.np_to_af_array(np.zeros((32,Data.shape[1]),dtype = np.float32)))\n",
    "Y = Constant(af.np_to_af_array(np.zeros((32,10),dtype = np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      " 51%|█████     | 665/1312 [00:50<00:48, 13.29it/s]"
     ]
    }
   ],
   "source": [
    "YP = learner(Xin,w)\n",
    "e = mse(Y,YP)\n",
    "acc = accuracy(Y,YP)\n",
    "sgd = SGD(lr = 0.01,momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1312 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 4/1312 [00:00<00:35, 37.23it/s]\u001b[A\n",
      "  1%|          | 8/1312 [00:00<00:35, 36.47it/s]\u001b[A\n",
      "  1%|          | 12/1312 [00:00<00:36, 35.73it/s]\u001b[A\n",
      "  1%|          | 16/1312 [00:00<00:37, 34.57it/s]\u001b[A\n",
      "  2%|▏         | 24/1312 [00:00<00:30, 41.63it/s]\u001b[A\n",
      "  3%|▎         | 33/1312 [00:00<00:26, 48.63it/s]\u001b[A\n",
      "  3%|▎         | 40/1312 [00:00<00:24, 52.11it/s]\u001b[A\n",
      "  4%|▎         | 46/1312 [00:00<00:24, 51.49it/s]\u001b[A\n",
      "  4%|▍         | 52/1312 [00:01<00:25, 49.22it/s]\u001b[A\n",
      "  4%|▍         | 58/1312 [00:01<00:26, 46.55it/s]\u001b[A\n",
      "  5%|▍         | 63/1312 [00:01<00:28, 43.14it/s]\u001b[A\n",
      "  5%|▌         | 68/1312 [00:01<00:30, 40.35it/s]\u001b[A\n",
      "  6%|▌         | 73/1312 [00:01<00:32, 37.61it/s]\u001b[A\n",
      "  6%|▌         | 77/1312 [00:01<00:35, 35.04it/s]\u001b[A\n",
      "  6%|▌         | 81/1312 [00:01<00:37, 33.04it/s]\u001b[A\n",
      "  6%|▋         | 85/1312 [00:02<00:39, 31.38it/s]\u001b[A\n",
      "  7%|▋         | 89/1312 [00:02<00:41, 29.75it/s]\u001b[A\n",
      "  7%|▋         | 93/1312 [00:02<00:43, 28.10it/s]\u001b[A\n",
      "  7%|▋         | 96/1312 [00:02<00:45, 26.96it/s]\u001b[A\n",
      "  8%|▊         | 99/1312 [00:02<00:46, 25.88it/s]\u001b[A\n",
      "  8%|▊         | 102/1312 [00:02<00:48, 24.89it/s]\u001b[A\n",
      "  8%|▊         | 105/1312 [00:02<00:50, 23.71it/s]\u001b[A\n",
      "  8%|▊         | 108/1312 [00:03<00:52, 22.97it/s]\u001b[A\n",
      "  8%|▊         | 111/1312 [00:03<00:54, 22.16it/s]\u001b[A\n",
      "  9%|▊         | 114/1312 [00:03<00:55, 21.73it/s]\u001b[A\n",
      "  9%|▉         | 121/1312 [00:03<00:43, 27.17it/s]\u001b[A\n",
      " 10%|▉         | 130/1312 [00:03<00:34, 34.04it/s]\u001b[A\n",
      " 10%|█         | 137/1312 [00:03<00:29, 39.27it/s]\u001b[A\n",
      " 11%|█         | 143/1312 [00:03<00:27, 42.66it/s]\u001b[A\n",
      " 11%|█▏        | 149/1312 [00:03<00:26, 43.92it/s]\u001b[A\n",
      " 12%|█▏        | 155/1312 [00:04<00:26, 43.02it/s]\u001b[A\n",
      " 12%|█▏        | 160/1312 [00:04<00:28, 40.11it/s]\u001b[A\n",
      "100%|██████████| 1312/1312 [00:36<00:00, 35.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.0\n",
      "Loss :0.0902527509223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    epoch_acc = []\n",
    "    epoch_loss = []\n",
    "    total_batchs = int(Data.shape[0]/32)\n",
    "    for j in tqdm.tqdm(range(total_batchs)):\n",
    "        X_np = Data[j*32:(j+1)*32,:]\n",
    "        Xin = Constant(af.np_to_af_array(X_np))\n",
    "        Y_np = classes[j*32:(j+1)*32,:]\n",
    "        Y = Constant(af.np_to_af_array(Y_np))\n",
    "        \n",
    "        YP = learner(Xin,w)\n",
    "        e = mse(Y,YP)\n",
    "        acc = accuracy(Y,YP)\n",
    "        (l,w) = sgd.update(e, w, i)\n",
    "        epoch_acc.append(acc)\n",
    "        epoch_loss.append(l)\n",
    "        \n",
    "    print('Accuracy :'+str(np.mean(epoch_acc)))\n",
    "    print('Loss :'+str(np.mean(epoch_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# input dataset\n",
    "X = np.array([  [0,0,1],\n",
    "                [0,1,1],\n",
    "                [1,0,1],\n",
    "                [1,1,1] ], dtype = np.float32)\n",
    "X = Constant(af.np_to_af_array(X))\n",
    "# output dataset            \n",
    "y = np.array([[0,0,1,1]], dtype = np.float32).T\n",
    "y = Constant(af.np_to_af_array(y)) \n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "syn0 = np.array(2*np.random.random((3,10)) - 1, dtype = np.float32)\n",
    "W1 = Variable(af.np_to_af_array(syn0),name='W1')\n",
    "b1 = Variable(af.constant(0,1),name='b1')\n",
    "\n",
    "syn0 = np.array(2*np.random.random((10,1)) - 1, dtype = np.float32)\n",
    "W2 = Variable(af.np_to_af_array(syn0),name='W2')\n",
    "b2 = Variable(af.constant(0,1),name='b2')\n",
    "\n",
    "w = [W1,b1,W2,b2]\n",
    "\n",
    "X1 = sigmoid(add(matmul(X,W1),b1))\n",
    "yp = sigmoid(add(matmul(X1,W2),b2))\n",
    "e = mse(y,yp)\n",
    "acc = accuracy(y,yp)\n",
    "sgd = SGD(lr = 0.001,momentum=0.99)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
