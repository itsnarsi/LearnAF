{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "\n",
    "import arrayfire as af\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from LearnAF import *\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "af.set_backend('cpu')\n",
    "\n",
    "DF = pd.read_csv('/home/narsi/Downloads/train.csv')\n",
    "Data = np.asarray(DF, dtype = np.float32)/255.0\n",
    "Data = Data[1:]\n",
    "labels = np.asarray(DF['label'], dtype = np.float32)\n",
    "classes = np.asarray(to_categorical(labels), dtype = np.float32)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "syn0 = np.array(2*np.random.random((Data.shape[1],64)) - 1, dtype = np.float32)\n",
    "W1 = Variable(af.np_to_af_array(syn0),name='W1')\n",
    "b1 = Variable(af.constant(0,1),name='b1')\n",
    "\n",
    "syn0 = np.array(2*np.random.random((64,16)) - 1, dtype = np.float32)\n",
    "W2 = Variable(af.np_to_af_array(syn0),name='W2')\n",
    "b2 = Variable(af.constant(0,1),name='b2')\n",
    "\n",
    "syn0 = np.array(2*np.random.random((16,10)) - 1, dtype = np.float32)\n",
    "W3 = Variable(af.np_to_af_array(syn0),name='W3')\n",
    "b3 = Variable(af.constant(0,1),name='b3')\n",
    "\n",
    "w = [W1,b1,W2,b2,W3,b3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learner(X,W):\n",
    "    # 784 -> 64\n",
    "    X1 = sigmoid(add(matmul(X,W[0]),W[1]))\n",
    "    # 64 -> 16\n",
    "    X2 = sigmoid(add(matmul(X1,W[2]),W[3]))\n",
    "    # 16 -> 10\n",
    "    YP = sigmoid(add(matmul(X2,W[4]),W[5]))\n",
    "    return YP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place Holders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xin = Constant(af.np_to_af_array(np.zeros((32,Data.shape[1]),dtype = np.float32)))\n",
    "Y = Constant(af.np_to_af_array(np.zeros((32,10),dtype = np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YP = learner(Xin,w)\n",
    "e = mse(Y,YP)\n",
    "acc = accuracy(Y,YP)\n",
    "sgd = SGD(lr = 0.01,momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1312/1312 [07:12<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.0133265054292\n",
      "Loss :0.155504283137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    epoch_acc = []\n",
    "    epoch_loss = []\n",
    "    total_batchs = int(Data.shape[0]/32)\n",
    "    for j in tqdm.tqdm(range(total_batchs)):\n",
    "        X_np = Data[j*32:(j+1)*32,:]\n",
    "        Xin = Constant(af.np_to_af_array(X_np))\n",
    "        Y_np = classes[j*32:(j+1)*32,:]\n",
    "        Y = Constant(af.np_to_af_array(Y_np))\n",
    "        \n",
    "        YP = learner(Xin,w)\n",
    "        e = mse(Y,YP)\n",
    "        acc = accuracy(Y,YP)\n",
    "        (l,w) = sgd.update(e, w, i)\n",
    "        epoch_acc.append(acc)\n",
    "        epoch_loss.append(l)\n",
    "        \n",
    "    print('Accuracy :'+str(np.mean(epoch_acc)))\n",
    "    print('Loss :'+str(np.mean(epoch_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arrayfire.Array()\n",
       "Type: float\n",
       "[32 10 1 1]\n",
       "    0.1504     0.0901     0.1558     0.1059     0.1361     0.1105     0.2130     0.1872     0.1224     0.2333 \n",
       "    0.3893     0.2263     0.1475     0.1284     0.2521     0.2955     0.0610     0.2050     0.0675     0.3252 \n",
       "    0.3853     0.0890     0.2221     0.0484     0.1704     0.2011     0.1356     0.1192     0.0698     0.3492 \n",
       "    0.3032     0.1950     0.2083     0.0730     0.2338     0.1424     0.0901     0.0673     0.0570     0.2785 \n",
       "    0.2970     0.0594     0.2872     0.1004     0.0858     0.1707     0.0763     0.2488     0.0627     0.1314 \n",
       "    0.3795     0.0663     0.1414     0.2606     0.1549     0.2069     0.0609     0.2193     0.1492     0.1535 \n",
       "    0.1556     0.1462     0.1148     0.0747     0.1392     0.1151     0.1892     0.1525     0.1030     0.3099 \n",
       "    0.4484     0.1195     0.0900     0.1049     0.0997     0.1477     0.0732     0.1164     0.0941     0.3506 \n",
       "    0.1830     0.0441     0.2904     0.1677     0.1085     0.1022     0.1074     0.1915     0.1750     0.0854 \n",
       "    0.3252     0.0647     0.0925     0.2196     0.1148     0.1449     0.1574     0.2171     0.1496     0.2989 \n",
       "    0.3121     0.1364     0.1401     0.1418     0.1873     0.1913     0.1041     0.1736     0.1217     0.3382 \n",
       "    0.2824     0.1738     0.2114     0.0601     0.1761     0.1166     0.0649     0.1154     0.0825     0.2227 \n",
       "    0.4389     0.1203     0.1708     0.0852     0.2061     0.1591     0.0542     0.0740     0.0888     0.3107 \n",
       "    0.1884     0.0976     0.2332     0.0713     0.2190     0.1445     0.2161     0.1943     0.0846     0.1909 \n",
       "    0.3261     0.0843     0.1814     0.0668     0.1334     0.1806     0.1079     0.1290     0.0517     0.1904 \n",
       "    0.2648     0.1911     0.2037     0.0441     0.1878     0.1672     0.1009     0.1201     0.0720     0.3479 \n",
       "    0.2321     0.1664     0.0527     0.1103     0.1726     0.1246     0.1639     0.1333     0.0474     0.5299 \n",
       "    0.3120     0.1049     0.1475     0.2490     0.2177     0.1167     0.0497     0.1051     0.2251     0.2216 \n",
       "    0.3253     0.1053     0.2572     0.0895     0.2018     0.1203     0.0706     0.1277     0.0785     0.2381 \n",
       "    0.2260     0.1273     0.3551     0.0399     0.2510     0.1245     0.1675     0.1323     0.0647     0.2612 \n",
       "    0.4038     0.1837     0.0296     0.1386     0.1124     0.1427     0.1049     0.1141     0.0668     0.6057 \n",
       "    0.3302     0.1847     0.2281     0.0852     0.2988     0.1628     0.0482     0.0838     0.0590     0.2217 \n",
       "    0.2160     0.1009     0.2828     0.0808     0.2397     0.1728     0.1198     0.2025     0.0426     0.2388 \n",
       "    0.4643     0.0576     0.4000     0.0830     0.1820     0.2019     0.0550     0.1499     0.1241     0.2098 \n",
       "    0.1694     0.1523     0.2532     0.0387     0.1914     0.1047     0.1517     0.1321     0.0736     0.2888 \n",
       "    0.1297     0.0985     0.3807     0.0517     0.2262     0.1570     0.0834     0.1124     0.0585     0.1528 \n",
       "    0.1887     0.0778     0.3112     0.0839     0.1636     0.1121     0.1574     0.1121     0.0673     0.2406 \n",
       "    0.1777     0.1148     0.4591     0.0310     0.2025     0.1463     0.1254     0.1565     0.0331     0.2431 \n",
       "    0.3296     0.1591     0.1822     0.1331     0.2163     0.1215     0.0496     0.1055     0.1722     0.4142 \n",
       "    0.1963     0.0497     0.4019     0.0405     0.1744     0.1981     0.0991     0.1042     0.0560     0.1949 \n",
       "    0.2496     0.2486     0.1187     0.3118     0.4676     0.2162     0.1110     0.1101     0.1645     0.3870 \n",
       "    0.2631     0.0856     0.0819     0.1799     0.1244     0.1989     0.1638     0.1593     0.1084     0.2429 \n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YP.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# input dataset\n",
    "X = np.array([  [0,0,1],\n",
    "                [0,1,1],\n",
    "                [1,0,1],\n",
    "                [1,1,1] ], dtype = np.float32)\n",
    "X = Constant(af.np_to_af_array(X))\n",
    "# output dataset            \n",
    "y = np.array([[0,0,1,1]], dtype = np.float32).T\n",
    "y = Constant(af.np_to_af_array(y)) \n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "syn0 = np.array(2*np.random.random((3,10)) - 1, dtype = np.float32)\n",
    "W1 = Variable(af.np_to_af_array(syn0),name='W1')\n",
    "b1 = Variable(af.constant(0,1),name='b1')\n",
    "\n",
    "syn0 = np.array(2*np.random.random((10,1)) - 1, dtype = np.float32)\n",
    "W2 = Variable(af.np_to_af_array(syn0),name='W2')\n",
    "b2 = Variable(af.constant(0,1),name='b2')\n",
    "\n",
    "w = [W1,b1,W2,b2]\n",
    "\n",
    "X1 = sigmoid(add(matmul(X,W1),b1))\n",
    "yp = sigmoid(add(matmul(X1,W2),b2))\n",
    "e = mse(y,yp)\n",
    "acc = accuracy(y,yp)\n",
    "sgd = SGD(lr = 0.001,momentum=0.99)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
